<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Convolutional-neural-network | Lucien</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="这篇文章将介绍卷积神经网络的概念及在 TensorFlow 中的使用方法。s(t) = (x * w)(t)x: 输入（input）w: 核函数（kernel function）输出，也被称作特征映射（feature map） 我们经常一次在多个维度上进行卷积运算。单独使用卷积运算在机器学习中是很少见的，卷积经常与其他函数一起使用。无论卷积运算是否对它的核进行了翻转，这些函数的组合通常是不可交换的">
<meta property="og:type" content="article">
<meta property="og:title" content="Convolutional-neural-network">
<meta property="og:url" content="https://lzk-ys.github.io/2018/10/31/Convolutional-neural-network/index.html">
<meta property="og:site_name" content="Lucien">
<meta property="og:description" content="这篇文章将介绍卷积神经网络的概念及在 TensorFlow 中的使用方法。s(t) = (x * w)(t)x: 输入（input）w: 核函数（kernel function）输出，也被称作特征映射（feature map） 我们经常一次在多个维度上进行卷积运算。单独使用卷积运算在机器学习中是很少见的，卷积经常与其他函数一起使用。无论卷积运算是否对它的核进行了翻转，这些函数的组合通常是不可交换的">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-11-15T10:47:43.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Convolutional-neural-network">
<meta name="twitter:description" content="这篇文章将介绍卷积神经网络的概念及在 TensorFlow 中的使用方法。s(t) = (x * w)(t)x: 输入（input）w: 核函数（kernel function）输出，也被称作特征映射（feature map） 我们经常一次在多个维度上进行卷积运算。单独使用卷积运算在机器学习中是很少见的，卷积经常与其他函数一起使用。无论卷积运算是否对它的核进行了翻转，这些函数的组合通常是不可交换的">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Lucien</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">个人博客</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://lzk-ys.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Convolutional-neural-network" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/31/Convolutional-neural-network/" class="article-date">
  <time datetime="2018-10-31T02:40:04.000Z" itemprop="datePublished">2018-10-31</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Convolutional-neural-network
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这篇文章将介绍卷积神经网络的概念及在 TensorFlow 中的使用方法。<br>s(t) = (x * w)(t)<br>x: 输入（input）<br>w: 核函数（kernel function）<br>输出，也被称作特征映射（feature map）</p>
<p>我们经常一次在多个维度上进行卷积运算。<br>单独使用卷积运算在机器学习中是很少见的，卷积经常与其他函数一起使用。无论卷积运算是否对它的核进行了翻转，这些函数的组合通常是不可交换的。</p>
<p>This keyword spotting(KWS) system runs on mobile devices, and therefore must have a small memory footprint and low computational power.<br>KWS 运行在移动设备上，应该有小的内存占用和低计算量。</p>
<p>This weight sharing helps to model local correlations in the input signal.<br>权重矩阵的共享有助于模拟输入信号中的局部相关性。</p>
<p>以下为 speech_commands 项目中，生成conv卷积模型的代码，对于其中用到的卷积原理和 TensorFlow API 我们将进行详细的讲解：</p>
<p>在这个模型中运行了两次卷积运算</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line">def create_conv_model(fingerprint_input, model_settings, is_training):</span><br><span class="line">    &quot;&quot;&quot;Builds a standard convolutional model.</span><br><span class="line"></span><br><span class="line">    This is roughly the network labeled as &apos;cnn-trad-fpool3&apos; in the</span><br><span class="line">    &apos;Convolutional Neural Networks for Small-footprint Keyword Spotting&apos; paper:</span><br><span class="line">    http://www.isca-speech.org/archive/interspeech_2015/papers/i15_1478.pdf</span><br><span class="line"></span><br><span class="line">    Here&apos;s the layout of the graph:</span><br><span class="line"></span><br><span class="line">    (fingerprint_input)</span><br><span class="line">          v</span><br><span class="line">      [Conv2D]&lt;-(weights)</span><br><span class="line">          v</span><br><span class="line">      [BiasAdd]&lt;-(bias)</span><br><span class="line">          v</span><br><span class="line">        [Relu]</span><br><span class="line">          v</span><br><span class="line">      [MaxPool]</span><br><span class="line">          v</span><br><span class="line">      [Conv2D]&lt;-(weights)</span><br><span class="line">          v</span><br><span class="line">      [BiasAdd]&lt;-(bias)</span><br><span class="line">          v</span><br><span class="line">        [Relu]</span><br><span class="line">          v</span><br><span class="line">      [MaxPool]</span><br><span class="line">          v</span><br><span class="line">      [MatMul]&lt;-(weights)</span><br><span class="line">          v</span><br><span class="line">      [BiasAdd]&lt;-(bias)</span><br><span class="line">          v</span><br><span class="line"></span><br><span class="line">    This produces fairly good quality results, but can involve a large number of</span><br><span class="line">    weight parameters and computations. For a cheaper alternative from the same</span><br><span class="line">    paper with slightly less accuracy, see &apos;low_latency_conv&apos; below.</span><br><span class="line"></span><br><span class="line">    这个模型产生了相当高质量的结果，但是会涉及大量的权重参数和计算量。对于一个可选的有更低精度的模型，请看 low_latency_conv 方法。</span><br><span class="line"></span><br><span class="line">    During training, dropout nodes are introduced after each relu, controlled by a placeholder.</span><br><span class="line"></span><br><span class="line">    在训练期间，在每个relu之后引入丢失节点（dropout nodes），由占位符控制。</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">    fingerprint_input: TensorFlow node that will output audio feature vectors.</span><br><span class="line">    TensorFlow 节点将要输出输出音频特征向量。</span><br><span class="line"></span><br><span class="line">    model_settings: Dictionary of information about the model.</span><br><span class="line">    关于模型的设置信息的字典</span><br><span class="line"></span><br><span class="line">    is_training: Whether the model is going to be used for training.</span><br><span class="line">    是否这个模型将要被用于训练</span><br><span class="line"></span><br><span class="line">    Returns:</span><br><span class="line">    TensorFlow node outputting logits results, and optionally a dropout</span><br><span class="line">    placeholder.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if is_training:</span><br><span class="line">        dropout_prob = tf.placeholder(tf.float32, name=&apos;dropout_prob&apos;)</span><br><span class="line">    input_frequency_size = model_settings[&apos;dct_coefficient_count&apos;]</span><br><span class="line">    input_time_size = model_settings[&apos;spectrogram_length&apos;]</span><br><span class="line">    fingerprint_4d = tf.reshape(fingerprint_input, [-1, input_time_size, input_frequency_size, 1])</span><br><span class="line"></span><br><span class="line">    first_filter_width = 8</span><br><span class="line">    first_filter_height = 20</span><br><span class="line">    first_filter_count = 64</span><br><span class="line">    first_weights = tf.Variable(</span><br><span class="line">        tf.truncated_normal(</span><br><span class="line">            [first_filter_height, first_filter_width, 1, first_filter_count],</span><br><span class="line">            stddev=0.01</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    first_bias = tf.Variable(tf.zeros([first_filter_count]))</span><br><span class="line">    first_conv = tf.nn.conv2d(fingerprint_4d, first_weights, [1, 1, 1, 1], &apos;SAME&apos;) + first_bias</span><br><span class="line">    first_relu = tf.nn.relu(first_conv)</span><br><span class="line">    if is_training:</span><br><span class="line">        first_dropout = tf.nn.dropout(first_relu, dropout_prob)</span><br><span class="line">    else:</span><br><span class="line">        first_dropout = first_relu</span><br><span class="line">    max_pool = tf.nn.max_pool(first_dropout, [1, 2, 2, 1], [1, 2, 2, 1], &apos;SAME&apos;)</span><br><span class="line">    second_filter_width = 4</span><br><span class="line">    second_filter_height = 10</span><br><span class="line">    second_filter_count = 64</span><br><span class="line">    second_weights = tf.Variable(</span><br><span class="line">        tf.truncated_normal(</span><br><span class="line">            [second_filter_height, second_filter_width, first_filter_count, second_filter_count],</span><br><span class="line">            stddev=0.01</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    second_bias = tf.Variable(tf.zeros(second_filter_count))</span><br><span class="line">    second_conv = tf.nn.conv2d(max_pool, second_weights, [1, 1, 1, 1], &apos;SAME&apos;) + second_bias</span><br><span class="line">    second_relu = tf.nn.relu(second_conv)</span><br><span class="line"></span><br><span class="line">    if is_training:</span><br><span class="line">        second_dropout = tf.nn.dropout(second_relu, dropout_prob)</span><br><span class="line">    else:</span><br><span class="line">        second_dropout = second_relu</span><br><span class="line"></span><br><span class="line">    second_conv_shape = second_dropout.get_shape()</span><br><span class="line">    second_conv_output_width = second_conv_shape[2]</span><br><span class="line">    second_conv_output_height = second_conv_shape[1]</span><br><span class="line">    second_conv_element_count = int(</span><br><span class="line">        second_conv_output_width * second_conv_output_height * second_filter_count</span><br><span class="line">    )</span><br><span class="line">    flattened_second_conv = tf.reshape(second_dropout, [-1, second_conv_element_count])</span><br><span class="line">    label_count = model_settings[&apos;label_count&apos;]</span><br><span class="line">    final_fc_weights = tf.Variable(</span><br><span class="line">        tf.truncated_normal(</span><br><span class="line">            [second_conv_element_count, label_count], stddev=0.01</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    final_fc_bias = tf.Variable(tf.zeros([label_count]))</span><br><span class="line">    final_fc = tf.matmul(flattened_second_conv, final_fc_weights) + final_fc_bias</span><br><span class="line"></span><br><span class="line">    if is_training:</span><br><span class="line">        return final_fc, dropout_prob</span><br><span class="line">    else:</span><br><span class="line">        return final_fc</span><br></pre></td></tr></table></figure>
<p>核心参数<br>dct_coefficient_count  频率大小，为什么默认为40 ？<br>sample_rate 音频的采样率，默认 16000，单位是 HZ/s<br>clip_duration_ms 样本音频的时长<br>window_size_ms ？？</p>
<p>weights<br>bias<br>超参数<br>fully connected 完全连接<br>ReLu(Rectified Linear Units)激活函数<br>dropout 消除过拟合</p>
<p>一个典型的卷积层包括三级：<br>一级：卷积操作，得到特征映射。<br>二级：非线性函数，例如：Relu 激活函数<br>三级：池化函数，最常见的是最大值池化和平均值池化</p>
<p>池化：<br>使用池化可以看作增加了一个无限强的先验：这一层学得的函数必须具有对少量平移的不变性。当这个假设成立时，池化可以极大地提高网络的统计效率。</p>
<p>在这种最常见的情况下，通过tf.truncated_normal函数初始化权重变量，给赋予的shape则是一个二维tensor，其中第一个维度代表该层中权重变量所连接（connect from）的单元数量，第二个维度代表该层中权重变量所连接到的（connect to）单元数量。</p>
<p>然后，通过tf.zeros函数初始化偏差变量（biases），确保所有偏差的起始值都是0，而它们的shape则是其在该层中所接到的（connect to）单元数量。</p>
<p>初始化全部的 tf.Variable实例，以下两种初始化变量的方法的区别：<br>sess.run(tf.initialize_all_variables())<br>sess.run(tf.global_variables_initializer())<br>sess.run()方法将会运行图表中与作为参数传入的操作相对应的完整子集。在初次调用时，init操作只包含了变量初始化程序tf.group。图表的其他部分不会在这里，而是在下面的训练循环运行。</p>
<p>我体会到各种教程中，会调用不同的 TF API 但是却没有对区别进行说明，很容易让读者产生困惑。</p>
<p>参数数量的计算方法<br>每一层参数个数 = 每一层的神经元的个数 * （每个神经元的权重数 + 1个偏差）</p>
<h4 id="权重矩阵初始化"><a href="#权重矩阵初始化" class="headerlink" title="权重矩阵初始化"></a>权重矩阵初始化</h4><p>权重矩阵 first_weights 的初始化，是通过 tf.truncated_normal()，即从截断的正态分布产生的随机值。<br>那么为什么要如此产生权重矩阵呢？</p>
<p>为什么使用卷积神经网络？<br>在处理图像这样的高维度输入时，让每个神经元都与前一层中的所有神经元进行全连接是不现实的。<br>用卷积神经网络隐藏层中的神经元将只与前一层中的一小块区域连接，而不是采取全连接方式。</p>
<p>卷积层和全连接层（CONV/FC）对输入执行变换操作的时候，不仅会用到激活函数，还会用到很多参数（神经元的突触权值和偏差）。而ReLU层和汇聚层则是进行一个固定不变的函数操作。卷积层和全连接层中的参数会随着梯度下降被训练，这样卷积神经网络计算出的分类评分就能和训练集中的每个图像的标签吻合了。</p>
<p>卷积层的参数是有一些可学习的滤波器集合构成的。每个滤波器在空间上（宽度和高度）都比较小，但是深度和输入数据一致。</p>
<p>卷积层中的每个神经元只观察输入数据中的一小部分。</p>
<p>3个超参数控制着输出数据体的尺寸：深度（depth），步长（stride）和零填充（zero-padding）<br>输出数据体在空间上的尺寸可以通过输入数据体尺寸（W），卷积层中神经元的感受野尺寸（F），步长（S）和零填充的数量（P）的函数来计算。</p>
<p>Keyword Spotting</p>
<p>CLSTM framework and multi-task Learing (MTL）framework</p>
<p>Recently, deep learning methods have been explored<br>for TDSV task where the DNN models are not directly used for<br>classification, but rather as a feature extractor which provides<br>speaker specific embeddings.</p>
<p>The performance of the DNN based approaches for TDSV<br>rely heavily on the availability of large amounts of background<br>training data. However, in many practical scenarios, the amount<br>of text dependent training data for background speakers would<br>be rather limited. In such a scenario, the GMM-UBM based<br>modeling continues to outperform the DNN based TDSV approaches<br>[9].<br>基于DNN的TDSV方法的性能高度依赖于大量的背景训练数据，而在实际场景中背景训练数据相当有限，基于GMM-UBM建模继续优于基于DNN的TDSV方法[9]。<br>原因： 使用 dropout 减少过度拟合，增加泛化的能力<br>This is primarily due to the over-training of the<br>DNN models on the training speakers and the DNN embeddings<br>do not generalize well to new speakers. The most common strategy<br>to overcome this is with pre-training and regularization approaches<br>like dropout [10]. For small amount of background<br>training, even with dropout methods, the DNN based models<br>(with the best choice of architecture and activation functions)<br>provides an equal error rate (EER) which is about twice the<br>GMM-UBM system [9].</p>
<p>The proposed model uses speech spectrogram<br>from a large contextual window (approximately of the duration<br>of the keyword of interest) processed with CNN feature embeddings<br>which are shared for both the KWS and TDSV tasks.<br>所提出的模型使用语音谱图<br>从一个大的上下文窗口（大约持续时间<br>感兴趣的关键词）用CNN特征嵌入处理<br>这些是KWS和TDSV任务共享的。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://lzk-ys.github.io/2018/10/31/Convolutional-neural-network/" data-id="cjvhtfus3000b09w9vt2mz0us" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/11/06/Back-Propagation-反向传播/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Back-Propagation-反向传播
        
      </div>
    </a>
  
  
    <a href="/2018/10/31/network-1/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">network</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    <!-- Featured Tags -->

  
    <!-- Short About -->
<section class="visible-md visible-lg">
    <h5><a href="/about/">ABOUT ME</a></h5>
    <div class="short-about">

        

        

        <!-- SNS Link -->
        <ul class="list-inline">
            
            
            

            

            

            
            
            
            
        </ul>
    </div>
</section>

  
    
  <h5>RECENT POSTS</h3>
  <div class="widget">
    <ul>
      
        <li>
          <a href="/2018/11/06/Back-Propagation-反向传播/">Back-Propagation-反向传播</a>
        </li>
      
        <li>
          <a href="/2018/10/31/Convolutional-neural-network/">Convolutional-neural-network</a>
        </li>
      
        <li>
          <a href="/2018/10/31/network-1/">network</a>
        </li>
      
        <li>
          <a href="/2018/10/31/network/">network</a>
        </li>
      
        <li>
          <a href="/2018/03/23/Android-开发手册/">Android 开发手册</a>
        </li>
      
    </ul>
  </div>

  
    <!-- Friends Blog -->

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">6</span></li></ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Lucien Liu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<script src="/js/script.js"></script>

  </div>
</body>
</html>